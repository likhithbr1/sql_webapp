# sql_chatbot_agent.py

from llama_cpp import Llama
from langchain_core.language_models.llms import LLM
from typing import Optional, List, Mapping, Any
from langchain_community.utilities import SQLDatabase
from langchain_community.agent_toolkits.sql.base import create_sql_agent
from langchain.agents.agent_types import AgentType

# ------------------ Config ------------------
LLAMA_MODEL_PATH = "sqlcoder-7b-2.Q4_K_M.gguf"
DB_URI = "mysql+pymysql://root:admin@localhost/chatbot"
N_CTX = 2048
N_THREADS = 8

# ------------------ Load SQLCoder GGUF ------------------
def load_llama(model_path: str):
    print(f"Loading SQLCoder model from {model_path} ‚Ä¶")
    return Llama(
        model_path=model_path,
        n_gpu_layers=0,       # CPU-only
        n_ctx=N_CTX,
        n_threads=N_THREADS,
        verbose=True,
        n_batch=512,
        use_mlock=True,
        use_mmap=True,
        logits_all=False,
    )

# ------------------ LLM Wrapper ------------------
class SQLCoderLLM(LLM):
    def __init__(self, model):
        self.model = model

    @property
    def _llm_type(self) -> str:
        return "sqlcoder-llama"

    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
        output = self.model(prompt, max_tokens=512, stop=stop)
        return output["choices"][0]["text"]

# ------------------ Main ------------------
def main():
    # Load model
    raw_model = load_llama(LLAMA_MODEL_PATH)
    llm = SQLCoderLLM(raw_model)

    # Connect to DB
    db = SQLDatabase.from_uri(DB_URI)

    # Create SQL agent
    agent_executor = create_sql_agent(
        llm=llm,
        db=db,
        agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
        verbose=True
    )

    # Accept user question
    question = input("‚ùì Ask a question about your database: ")

    # Get result
    result = agent_executor.invoke({"input": question})
    print("\nüìä Answer:")
    print(result)

if __name__ == "__main__":
    main()

